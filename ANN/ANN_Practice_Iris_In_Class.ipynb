{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dd8f06-6a82-4d2b-b5aa-e9630e879a4d",
   "metadata": {},
   "source": [
    "# Multi-Class Classification Exercise with ANN using PyTorch\n",
    "\n",
    "## 1. Load and View the Data:\n",
    "\n",
    "Read the Iris dataset from a CSV file using pandas.\n",
    "Display the first few rows of the dataset to understand its structure.\n",
    "\n",
    "## 2. Preprocess Data:\n",
    "\n",
    "Scale the feature values using StandardScaler.\n",
    "Split the dataset into features (X) and target (y).\n",
    "Convert the target labels into a format suitable for PyTorch (e.g., one-hot encoding or integer labels).\n",
    "\n",
    "## 3. Build the Model:\n",
    "\n",
    "Define an Artificial Neural Network (ANN) architecture using PyTorch.\n",
    "Include appropriate layers and activation functions for multi-class classification.\n",
    "\n",
    "## 4. Train the Model:\n",
    "\n",
    "Split the data into training and testing sets.\n",
    "Train the ANN using the training data and implement a suitable optimizer and loss function (e.g., CrossEntropyLoss).\n",
    "\n",
    "## 5. Test the Model:\n",
    "\n",
    "Use the trained model to make predictions on the testing data.\n",
    "\n",
    "## 6. Evaluate Performance:\n",
    "\n",
    "Calculate performance metrics such as accuracy, precision, recall, and F1-score.\n",
    "Display the evaluation results to assess model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89288f24-4837-4a3f-b8fe-2d4d7b13348e",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## The data set consists of 150 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "Content\n",
    "## The dataset contains a set of 150 records under 5 attributes - Petal Length, Petal Width, Sepal Length, Sepal width and Class(Species).\n",
    "\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8e2b6-5b5a-428a-a674-a3aa2cde193f",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8909e8-7247-443c-82df-743020eb50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c811f1-cc7b-45ff-bc57-f65a7bbd0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1f663-c441-4b66-9cbd-96d4c54a1dc3",
   "metadata": {},
   "source": [
    "## Load the Iris dataset from the 'Iris.csv' file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66575048-af56-4eb6-a833-035f662a863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f9067-dab5-4e47-89e3-7c991927a148",
   "metadata": {},
   "source": [
    "## Display the first few rows of the Iris dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac4d922-cedb-47c4-a08a-d6f983fa4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe head function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ccb99-c0db-469e-84da-debb21eec379",
   "metadata": {},
   "source": [
    "## Print general information, missing values, and shape of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25de4066-a26b-4867-b7b9-e935d7f6ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_info_dataframe(dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c0113b-4bf4-405c-8367-4032d265ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_info_dataframe(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f0dbe-86ea-4799-96fe-e69b1af05194",
   "metadata": {},
   "source": [
    "## Retrieve and display the unique species in the Iris dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b28aa7-4319-4552-8168-e5f53d3cb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe unique function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69797e-63ed-407e-806b-f8ddd14f7451",
   "metadata": {},
   "source": [
    "## LabelEncoding The Attributes of The Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7676c0-48ed-4d3a-a0ea-159ed27b29bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris_df['Species'] = iris_df['Species'].map({'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2})\n",
    "iris_df['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1bfe5f5-bb2d-49e2-939c-8b6fdcda2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a01fe4-6113-4f79-9203-d23d5070945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe head function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571fd252-6ed3-4871-bfa7-0f83931ab873",
   "metadata": {},
   "source": [
    "## Drop the 'Id' column from the Iris dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a144100-d8c4-46fd-95fc-963baa54f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe drop function, use inplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79a3aac-4a86-4316-a854-434b8bf70158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe head function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a0dfe8-bba8-4445-bfb5-9f04a9dd16a6",
   "metadata": {},
   "source": [
    "## Split the Iris dataframe into features (X) by dropping the 'Species' column and extracting its values.  \n",
    "## Extract the target (y) by selecting only the 'Species' column and converting it into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "965b5f4d-d8a8-43a4-9b35-c740f731bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe values attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f4929-87bb-4358-b23f-9c7589e01e01",
   "metadata": {},
   "source": [
    "## Alternatively, use to_numpy() instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e9289d-fd22-42a3-8f79-af22f3ab1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = iris_df.drop([\"Species\"], axis=1).to_numpy()\n",
    "# y = iris_df[\"Species\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bffd5d-6f38-4e6f-8f09-d525dbb3d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9818a1-defd-4fb5-82c2-adea26206ce3",
   "metadata": {},
   "source": [
    "## Import standarscaler and train_test_split library\n",
    "## Initialize a StandardScaler object for feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421a016c-95f4-43f7-98b8-1dd6724b2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cbce68f-b1c7-4b35-adce-26f869e18cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object for scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a9129-d839-4655-9b26-b71ad48ea7a7",
   "metadata": {},
   "source": [
    "## Doing The Train Test Split And Scaling The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31e6012d-5ec3-4964-b596-b1a28c544fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc63995-8b51-45d2-ab68-4685067aafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e91961-247e-4361-81a7-0a1c4001cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f644903-2305-4969-815b-0b4ee3d26003",
   "metadata": {},
   "source": [
    "# Task: Create a Custom Dataset Class for PyTorch\n",
    "Objective:\n",
    "The task is to create a custom dataset class, CustomDataset, by inheriting from PyTorch's Dataset class. This class is designed to handle input features and corresponding labels for a machine learning model.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Initialize the class with two inputs: features (input data) and labels (target values).\n",
    "Convert both features and labels to PyTorch tensors with appropriate data types (float32 for features and long for labels).\n",
    "Implement the __len__ method to return the number of samples in the dataset.\n",
    "Implement the __getitem__ method to retrieve a single sample (feature and label pair) by its index.\n",
    "Expected Behavior:\n",
    "\n",
    "When the dataset object is created, it should store the input data and labels as tensors.\n",
    "Calling the len() function on the dataset object should return the total number of samples.\n",
    "Accessing a sample using an index (like dataset[0]) should return a tuple containing the feature and label at that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ea4ae3-15aa-4c0a-a6ac-b56a2c508357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CustomDataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c5b16-6db7-4164-974c-88ccf3a987f5",
   "metadata": {},
   "source": [
    "## Create a train_dataset object using the CustomDataset class with training features (X_train) and labels (y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce2de158-ef26-4016-a667-167cdc63263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e80ef9-6708-4356-bdb9-fc657934a535",
   "metadata": {},
   "source": [
    "## Get the total number of samples in the train_dataset using the len() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8256e8ec-b756-4fd7-ad78-ad7a97393ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa79671-77c5-4de8-b1fd-f5c7d9c75511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf9eaf4e-5b1f-4b09-b19e-ae6bb2add238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7baf50-c82b-4760-a3c3-c39dde737f4a",
   "metadata": {},
   "source": [
    "## Access the first sample (features and label) from the train_dataset using index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61254ea-b073-4e98-a7e3-38e908d82fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6a8a897-1eaa-4b30-b2e4-7c4470a3db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sample features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6586ac1-88b0-4f04-8f9a-b742847fcb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sample labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a070193-7e1b-40a1-b2cb-a730fe102352",
   "metadata": {},
   "source": [
    "## Create a test_dataset object using the CustomDataset class with test features (X_test) and labels (y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c221649-ce5b-4f2b-b290-28e516f0215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test_dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c04791-59d9-4b24-b36e-1d231b8a17e9",
   "metadata": {},
   "source": [
    "## Get the total number of samples in the test_dataset using the len() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74f66be7-60dd-4a2e-82bd-9fcd06b74498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a087e36b-b9ae-4c6d-b37b-80c96edcc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b26a940-5258-4dd1-b65d-19782f09ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0663d3-9ed8-457e-bc4c-bc59f7658783",
   "metadata": {},
   "source": [
    "# Create DataLoaders for Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fafb0-1599-4559-b878-a60375189693",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "### The task is to create a DataLoader for the training dataset (train_dataset) to:\n",
    "\n",
    "### Load data in batches of size 16.\n",
    "### Shuffle the data to ensure randomness during training.\n",
    "### Facilitate mini-batch gradient descent by processing data in smaller chunks instead of loading the entire dataset at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca8bdfe8-9e37-4587-9add-57a6fa4665cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7101af7-4604-4bf1-b22e-c343ced2112d",
   "metadata": {},
   "source": [
    "## The task is to get the total number of batches in the training data loader (train_loader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15fc5b06-4af1-493c-8d11-3b044b99de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb30ad1-2206-42d4-9607-a93a0eae8dac",
   "metadata": {},
   "source": [
    "## Create DataLoader for Testing Dataset\n",
    "### Objective:\n",
    "### The task is to create a DataLoader for the testing dataset (test_dataset) to:\n",
    "\n",
    "### Load test data in batches of size 16.\n",
    "### Do not shuffle the data (shuffle=False) to ensure consistent and repeatable evaluation.\n",
    "### Facilitate batch-wise inference without altering the order of test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "150a3acb-bd37-43d8-8250-f01d1ecec852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708a5f2-ab39-4aff-83ca-fe9901c2f94f",
   "metadata": {},
   "source": [
    "## The task is to get the total number of batches in the testing data loader (test_loader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceff18cc-0555-4e21-9b19-68a52c8977c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa37b36-cbea-4d1a-9d56-125d552cfb9b",
   "metadata": {},
   "source": [
    "# Creating Our Neural Network Model For Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2416bb-0e39-4b34-8d45-67b560470d0c",
   "metadata": {},
   "source": [
    "### Build an Artificial Neural Network (ANN) for Classification\n",
    "## Objective:\n",
    "The task is to create an ANN model using PyTorch's nn.Module class with:\n",
    "\n",
    "### Input layer: Accepts input of size input_dim.\n",
    "### Hidden Layer 1: Contains 128 neurons with ReLU activation.\n",
    "### Hidden Layer 2: Contains 64 neurons with ReLU activation.\n",
    "### Output Layer: Contains output_dim neurons to produce the final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c908ab6-aa9c-49c3-b693-293f68c4664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301c476-e932-4bd9-a9df-7ff3fe5416e3",
   "metadata": {},
   "source": [
    "## Instantiate Our Neural Network Model with proper dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea34ed78-a6d3-435d-a48a-6e828f91e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = 4 because we have 4 inputs namely sepal_length,sepal_width,petal_length,petal_width\n",
    "# output_dim = 3 because we have namely 3 categories setosa,versicolor and virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f498de-e2fc-4fd8-8f19-59f2dc8c2e36",
   "metadata": {},
   "source": [
    "### Set the Learning Rate: Define the learning rate for the optimization process.\n",
    "### Initialize the Loss Function: Create a loss function object using CrossEntropyLoss for multi-class classification tasks.\n",
    "### Create the Optimizer: Initialize the Adam optimizer with the model's parameters and the specified learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bda98e7a-f09a-4383-a2ec-cec199fc0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our optimizer and loss function object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1ebaa-f7ec-4abd-97f9-3eac1cc35950",
   "metadata": {},
   "source": [
    "# Lets train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e035a-91fd-4ee4-9950-79a5c938d592",
   "metadata": {},
   "source": [
    "## Train the ANN Model Using Mini-Batch Gradient Descent\n",
    "### Objective:\n",
    "The task is to train the ANN model for a specified number of epochs using mini-batch gradient descent. In each epoch:\n",
    "\n",
    "### Iterate through batches: Use a for loop to access training data in batches from the train_loader.\n",
    "### Forward pass: Compute predictions using the model.\n",
    "### Calculate loss: Measure the error using the loss function.\n",
    "### Backward pass: Compute gradients using loss.backward().\n",
    "### Update weights: Adjust model parameters using the optimizer.\n",
    "### Track loss: Accumulate batch losses and calculate the average loss per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df5c2eaa-f972-4c0c-bd15-ad262080d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7a4c9-910f-4225-8e95-9dff316b638c",
   "metadata": {},
   "source": [
    "## Set the Model to Evaluation Mode\n",
    "### Objective:\n",
    "The task is to set the model to evaluation mode using model.eval() before making predictions or evaluating performance on test data.\n",
    "\n",
    "### Reason:\n",
    "Switching to evaluation mode disables certain training-specific behaviors like dropout and batch normalization updates, ensuring consistent and reliable model predictions during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d2fca7b-0a7f-4ca1-9f3b-df2a2d4fac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model to eval mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb31419-fe83-48dc-a067-3c87327f73a2",
   "metadata": {},
   "source": [
    "## Evaluate the Model Performance on Test Data\n",
    "### Objective:\n",
    "The task is to evaluate the trained model's performance on the test data using mini-batches from the test_loader.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "### Disable gradient calculation: Use torch.no_grad() to prevent gradient updates during evaluation.\n",
    "### Forward pass: Generate predictions for each batch of test data.\n",
    "### Calculate accuracy: Compare predicted labels with actual labels, accumulate correct predictions, and compute the overall test accuracy.\n",
    "### Print accuracy: Display the test accuracy rounded to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ade0cc3-98ee-4dc2-a574-ed0748607fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation code\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "#predictions in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69336c-1591-48eb-8c90-8cec7af6bf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
