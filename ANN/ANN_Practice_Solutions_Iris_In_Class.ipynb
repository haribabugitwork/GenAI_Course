{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dd8f06-6a82-4d2b-b5aa-e9630e879a4d",
   "metadata": {},
   "source": [
    "# Multi-Class Classification Exercise with ANN using PyTorch\n",
    "\n",
    "## 1. Load and View the Data:\n",
    "\n",
    "Read the Iris dataset from a CSV file using pandas.\n",
    "Display the first few rows of the dataset to understand its structure.\n",
    "\n",
    "## 2. Preprocess Data:\n",
    "\n",
    "Scale the feature values using StandardScaler.\n",
    "Split the dataset into features (X) and target (y).\n",
    "Convert the target labels into a format suitable for PyTorch (e.g., one-hot encoding or integer labels).\n",
    "\n",
    "## 3. Build the Model:\n",
    "\n",
    "Define an Artificial Neural Network (ANN) architecture using PyTorch.\n",
    "Include appropriate layers and activation functions for multi-class classification.\n",
    "\n",
    "## 4. Train the Model:\n",
    "\n",
    "Split the data into training and testing sets.\n",
    "Train the ANN using the training data and implement a suitable optimizer and loss function (e.g., CrossEntropyLoss).\n",
    "\n",
    "## 5. Test the Model:\n",
    "\n",
    "Use the trained model to make predictions on the testing data.\n",
    "\n",
    "## 6. Evaluate Performance:\n",
    "\n",
    "Calculate performance metrics such as accuracy, precision, recall, and F1-score.\n",
    "Display the evaluation results to assess model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89288f24-4837-4a3f-b8fe-2d4d7b13348e",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## The data set consists of 150 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "Content\n",
    "## The dataset contains a set of 150 records under 5 attributes - Petal Length, Petal Width, Sepal Length, Sepal width and Class(Species).\n",
    "\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8e2b6-5b5a-428a-a674-a3aa2cde193f",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a10414c-7c94-4d2f-b038-96e10161600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a5a60f-7edf-4925-a496-2b05772d3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1f663-c441-4b66-9cbd-96d4c54a1dc3",
   "metadata": {},
   "source": [
    "## Load the Iris dataset from the 'Iris.csv' file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66575048-af56-4eb6-a833-035f662a863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f9067-dab5-4e47-89e3-7c991927a148",
   "metadata": {},
   "source": [
    "## Display the first few rows of the Iris dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d50b49-8d02-43cf-810e-3678cd88584f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ccb99-c0db-469e-84da-debb21eec379",
   "metadata": {},
   "source": [
    "## Print general information, missing values, and shape of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25de4066-a26b-4867-b7b9-e935d7f6ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_dataframe(dataframe):\n",
    "    print(f\"DATAFRAME GENERAL INFO - \\n\")\n",
    "    print(dataframe.info(),\"\\n\")\n",
    "    print(f\"DATAFRAME MISSING INFO - \\n\")\n",
    "    print(dataframe.isnull().sum(),\"\\n\")\n",
    "    print(f\"DATAFRAME SHAPE INFO - \\n\")\n",
    "    print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c0113b-4bf4-405c-8367-4032d265ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME GENERAL INFO - \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n",
      "None \n",
      "\n",
      "DATAFRAME MISSING INFO - \n",
      "\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64 \n",
      "\n",
      "DATAFRAME SHAPE INFO - \n",
      "\n",
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "get_info_dataframe(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f0dbe-86ea-4799-96fe-e69b1af05194",
   "metadata": {},
   "source": [
    "## Retrieve and display the unique species in the Iris dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b28aa7-4319-4552-8168-e5f53d3cb055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['Species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69797e-63ed-407e-806b-f8ddd14f7451",
   "metadata": {},
   "source": [
    "## LabelEncoding The Attributes of The Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7676c0-48ed-4d3a-a0ea-159ed27b29bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris_df['Species'] = iris_df['Species'].map({'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2})\n",
    "iris_df['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1bfe5f5-bb2d-49e2-939c-8b6fdcda2fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming iris_df is your DataFrame\n",
    "label_encoder = LabelEncoder()\n",
    "iris_df['Species'] = label_encoder.fit_transform(iris_df['Species'])\n",
    "iris_df['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a01fe4-6113-4f79-9203-d23d5070945b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0   1            5.1           3.5            1.4           0.2        0\n",
       "1   2            4.9           3.0            1.4           0.2        0\n",
       "2   3            4.7           3.2            1.3           0.2        0\n",
       "3   4            4.6           3.1            1.5           0.2        0\n",
       "4   5            5.0           3.6            1.4           0.2        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571fd252-6ed3-4871-bfa7-0f83931ab873",
   "metadata": {},
   "source": [
    "## Drop the 'Id' column from the Iris dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a144100-d8c4-46fd-95fc-963baa54f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79a3aac-4a86-4316-a854-434b8bf70158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0            5.1           3.5            1.4           0.2        0\n",
       "1            4.9           3.0            1.4           0.2        0\n",
       "2            4.7           3.2            1.3           0.2        0\n",
       "3            4.6           3.1            1.5           0.2        0\n",
       "4            5.0           3.6            1.4           0.2        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a0dfe8-bba8-4445-bfb5-9f04a9dd16a6",
   "metadata": {},
   "source": [
    "## Split the Iris dataframe into features (X) by dropping the 'Species' column and extracting its values.  \n",
    "## Extract the target (y) by selecting only the 'Species' column and converting it into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "965b5f4d-d8a8-43a4-9b35-c740f731bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df.drop([\"Species\"],axis=1).values\n",
    "y = iris_df[\"Species\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f4929-87bb-4358-b23f-9c7589e01e01",
   "metadata": {},
   "source": [
    "## Alternatively, use to_numpy() instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e9289d-fd22-42a3-8f79-af22f3ab1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = iris_df.drop([\"Species\"], axis=1).to_numpy()\n",
    "# y = iris_df[\"Species\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bffd5d-6f38-4e6f-8f09-d525dbb3d0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9818a1-defd-4fb5-82c2-adea26206ce3",
   "metadata": {},
   "source": [
    "## Import standarscaler and train_test_split library\n",
    "## Initialize a StandardScaler object for feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421a016c-95f4-43f7-98b8-1dd6724b2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cbce68f-b1c7-4b35-adce-26f869e18cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a9129-d839-4655-9b26-b71ad48ea7a7",
   "metadata": {},
   "source": [
    "## Doing The Train Test Split And Scaling The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31e6012d-5ec3-4964-b596-b1a28c544fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc63995-8b51-45d2-ab68-4685067aafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e91961-247e-4361-81a7-0a1c4001cdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 4), (105,), (45, 4), (45,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f644903-2305-4969-815b-0b4ee3d26003",
   "metadata": {},
   "source": [
    "# Task: Create a Custom Dataset Class for PyTorch\n",
    "Objective:\n",
    "The task is to create a custom dataset class, CustomDataset, by inheriting from PyTorch's Dataset class. This class is designed to handle input features and corresponding labels for a machine learning model.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Initialize the class with two inputs: features (input data) and labels (target values).\n",
    "Convert both features and labels to PyTorch tensors with appropriate data types (float32 for features and long for labels).\n",
    "Implement the __len__ method to return the number of samples in the dataset.\n",
    "Implement the __getitem__ method to retrieve a single sample (feature and label pair) by its index.\n",
    "Expected Behavior:\n",
    "\n",
    "When the dataset object is created, it should store the input data and labels as tensors.\n",
    "Calling the len() function on the dataset object should return the total number of samples.\n",
    "Accessing a sample using an index (like dataset[0]) should return a tuple containing the feature and label at that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ea4ae3-15aa-4c0a-a6ac-b56a2c508357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CustomDataset Class\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        # print(\"Someone called me len..\")\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c5b16-6db7-4164-974c-88ccf3a987f5",
   "metadata": {},
   "source": [
    "## Create a train_dataset object using the CustomDataset class with training features (X_train) and labels (y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce2de158-ef26-4016-a667-167cdc63263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_dataset object\n",
    "train_dataset = CustomDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e80ef9-6708-4356-bdb9-fc657934a535",
   "metadata": {},
   "source": [
    "## Get the total number of samples in the train_dataset using the len() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8256e8ec-b756-4fd7-ad78-ad7a97393ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa79671-77c5-4de8-b1fd-f5c7d9c75511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf9eaf4e-5b1f-4b09-b19e-ae6bb2add238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7baf50-c82b-4760-a3c3-c39dde737f4a",
   "metadata": {},
   "source": [
    "## Access the first sample (features and label) from the train_dataset using index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61254ea-b073-4e98-a7e3-38e908d82fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3130, 0.1519, 0.8127, 1.5676]), tensor(2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6a8a897-1eaa-4b30-b2e4-7c4470a3db2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3130, 0.1519, 0.8127, 1.5676])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6586ac1-88b0-4f04-8f9a-b742847fcb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a070193-7e1b-40a1-b2cb-a730fe102352",
   "metadata": {},
   "source": [
    "## Create a test_dataset object using the CustomDataset class with test features (X_test) and labels (y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c221649-ce5b-4f2b-b290-28e516f0215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test_dataset object\n",
    "test_dataset = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c04791-59d9-4b24-b36e-1d231b8a17e9",
   "metadata": {},
   "source": [
    "## Get the total number of samples in the test_dataset using the len() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74f66be7-60dd-4a2e-82bd-9fcd06b74498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a087e36b-b9ae-4c6d-b37b-80c96edcc9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b26a940-5258-4dd1-b65d-19782f09ef8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0663d3-9ed8-457e-bc4c-bc59f7658783",
   "metadata": {},
   "source": [
    "# Create DataLoaders for Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fafb0-1599-4559-b878-a60375189693",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "### The task is to create a DataLoader for the training dataset (train_dataset) to:\n",
    "\n",
    "### Load data in batches of size 16.\n",
    "### Shuffle the data to ensure randomness during training.\n",
    "### Facilitate mini-batch gradient descent by processing data in smaller chunks instead of loading the entire dataset at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca8bdfe8-9e37-4587-9add-57a6fa4665cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7101af7-4604-4bf1-b22e-c343ced2112d",
   "metadata": {},
   "source": [
    "## The task is to get the total number of batches in the training data loader (train_loader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15fc5b06-4af1-493c-8d11-3b044b99de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb30ad1-2206-42d4-9607-a93a0eae8dac",
   "metadata": {},
   "source": [
    "## Create DataLoader for Testing Dataset\n",
    "### Objective:\n",
    "### The task is to create a DataLoader for the testing dataset (test_dataset) to:\n",
    "\n",
    "### Load test data in batches of size 16.\n",
    "### Do not shuffle the data (shuffle=False) to ensure consistent and repeatable evaluation.\n",
    "### Facilitate batch-wise inference without altering the order of test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "150a3acb-bd37-43d8-8250-f01d1ecec852",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708a5f2-ab39-4aff-83ca-fe9901c2f94f",
   "metadata": {},
   "source": [
    "## The task is to get the total number of batches in the testing data loader (test_loader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceff18cc-0555-4e21-9b19-68a52c8977c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa37b36-cbea-4d1a-9d56-125d552cfb9b",
   "metadata": {},
   "source": [
    "# Creating Our Neural Network Model For Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2416bb-0e39-4b34-8d45-67b560470d0c",
   "metadata": {},
   "source": [
    "### Build an Artificial Neural Network (ANN) for Classification\n",
    "## Objective:\n",
    "The task is to create an ANN model using PyTorch's nn.Module class with:\n",
    "\n",
    "### Input layer: Accepts input of size input_dim.\n",
    "### Hidden Layer 1: Contains 128 neurons with ReLU activation.\n",
    "### Hidden Layer 2: Contains 64 neurons with ReLU activation.\n",
    "### Output Layer: Contains output_dim neurons to produce the final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c908ab6-aa9c-49c3-b693-293f68c4664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_ClassificationModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(ANN_ClassificationModel,self).__init__()\n",
    "        self.input_layer    = nn.Linear(input_dim,128)\n",
    "        self.hidden_layer1  = nn.Linear(128,64)\n",
    "        self.output_layer   = nn.Linear(64,output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out =  self.relu(self.input_layer(x))\n",
    "        out =  self.relu(self.hidden_layer1(out))\n",
    "        out =  self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301c476-e932-4bd9-a9df-7ff3fe5416e3",
   "metadata": {},
   "source": [
    "## Instantiate Our Neural Network Model with proper dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea34ed78-a6d3-435d-a48a-6e828f91e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = 4 because we have 4 inputs namely sepal_length,sepal_width,petal_length,petal_width\n",
    "# output_dim = 3 because we have namely 3 categories setosa,versicolor and virginica\n",
    "input_dim  = 4 \n",
    "output_dim = 3\n",
    "model = ANN_ClassificationModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f498de-e2fc-4fd8-8f19-59f2dc8c2e36",
   "metadata": {},
   "source": [
    "### Set the Learning Rate: Define the learning rate for the optimization process.\n",
    "### Initialize the Loss Function: Create a loss function object using CrossEntropyLoss for multi-class classification tasks.\n",
    "### Create the Optimizer: Initialize the Adam optimizer with the model's parameters and the specified learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bda98e7a-f09a-4383-a2ec-cec199fc0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our optimizer and loss function object\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1ebaa-f7ec-4abd-97f9-3eac1cc35950",
   "metadata": {},
   "source": [
    "# Lets train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e035a-91fd-4ee4-9950-79a5c938d592",
   "metadata": {},
   "source": [
    "## Train the ANN Model Using Mini-Batch Gradient Descent\n",
    "### Objective:\n",
    "The task is to train the ANN model for a specified number of epochs using mini-batch gradient descent. In each epoch:\n",
    "\n",
    "### Iterate through batches: Use a for loop to access training data in batches from the train_loader.\n",
    "### Forward pass: Compute predictions using the model.\n",
    "### Calculate loss: Measure the error using the loss function.\n",
    "### Backward pass: Compute gradients using loss.backward().\n",
    "### Update weights: Adjust model parameters using the optimizer.\n",
    "### Track loss: Accumulate batch losses and calculate the average loss per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df5c2eaa-f972-4c0c-bd15-ad262080d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 0.6131816974708012\n",
      "Epoch: 2 , Loss: 0.2717244763459478\n",
      "Epoch: 3 , Loss: 0.15053462982177734\n",
      "Epoch: 4 , Loss: 0.08052255106823784\n",
      "Epoch: 5 , Loss: 0.06847730804500836\n",
      "Epoch: 6 , Loss: 0.13263878851596797\n",
      "Epoch: 7 , Loss: 0.0386316878721118\n",
      "Epoch: 8 , Loss: 0.05146951058746448\n",
      "Epoch: 9 , Loss: 0.08523762006578701\n",
      "Epoch: 10 , Loss: 0.06573745408760649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NVSHARE][WARN]: Couldn't open file /var/run/secrets/kubernetes.io/serviceaccount/namespace to read Pod namespace\n",
      "[NVSHARE][INFO]: Successfully initialized nvshare GPU\n",
      "[NVSHARE][INFO]: Client ID = b74e0c4d644f89ae\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_epoch_loss = 0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        \n",
    "        #forward feed\n",
    "        y_pred = model(batch_features)\n",
    "        #calculate the loss\n",
    "        loss = criterion(y_pred, batch_labels)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        # backward propagation: calculate gradients\n",
    "        # update the weights\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_epoch_loss = total_epoch_loss + loss.item()\n",
    "\n",
    "       \n",
    "    avg_loss = total_epoch_loss/len(train_loader)\n",
    "    print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7a4c9-910f-4225-8e95-9dff316b638c",
   "metadata": {},
   "source": [
    "## Set the Model to Evaluation Mode\n",
    "### Objective:\n",
    "The task is to set the model to evaluation mode using model.eval() before making predictions or evaluating performance on test data.\n",
    "\n",
    "### Reason:\n",
    "Switching to evaluation mode disables certain training-specific behaviors like dropout and batch normalization updates, ensuring consistent and reliable model predictions during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d2fca7b-0a7f-4ca1-9f3b-df2a2d4fac07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANN_ClassificationModel(\n",
       "  (input_layer): Linear(in_features=4, out_features=128, bias=True)\n",
       "  (hidden_layer1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model to eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb31419-fe83-48dc-a067-3c87327f73a2",
   "metadata": {},
   "source": [
    "## Evaluate the Model Performance on Test Data\n",
    "### Objective:\n",
    "The task is to evaluate the trained model's performance on the test data using mini-batches from the test_loader.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "### Disable gradient calculation: Use torch.no_grad() to prevent gradient updates during evaluation.\n",
    "### Forward pass: Generate predictions for each batch of test data.\n",
    "### Calculate accuracy: Compare predicted labels with actual labels, accumulate correct predictions, and compute the overall test accuracy.\n",
    "### Print accuracy: Display the test accuracy rounded to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ade0cc3-98ee-4dc2-a574-ed0748607fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# evaluation code\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "#predictions in data\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "\n",
    "        outputs = model(batch_features)\n",
    "        # print(outputs)\n",
    "        max_logit, predicted = torch.max(outputs, dim=1)\n",
    "        # print(max_logit)\n",
    "        # print(predicted)\n",
    "        total = total + batch_labels.shape[0]\n",
    "\n",
    "        correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "test_accuracy = correct/total\n",
    "print(f\"Test Accuracy: {round(test_accuracy, 2)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69336c-1591-48eb-8c90-8cec7af6bf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
