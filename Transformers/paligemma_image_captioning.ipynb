{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 Image Captioning with Google PaLI-Gemma\n",
        "This notebook demonstrates how to use the `google/paligemma-3b-pt-224` model from Hugging Face for image captioning using PyTorch.\n",
        "We'll walk through loading the model, preprocessing an image, generating a description, and displaying the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries if not already installed\n",
        "!pip install transformers pillow torch huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd10 Authenticate with Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Replace with your actual token\n",
        "HF_TOKEN = \"hf_your_token_here\"\n",
        "login(token=HF_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Load the Model and Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "import torch\n",
        "\n",
        "model_id = \"google/paligemma-3b-pt-224\"\n",
        "processor = AutoProcessor.from_pretrained(model_id, token=HF_TOKEN)\n",
        "model = AutoModelForVision2Seq.from_pretrained(\n",
        "    model_id,\n",
        "    token=HF_TOKEN,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udda5\ufe0f Move Model to Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\uddbc\ufe0f Load and Preprocess Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Replace with your own image path\n",
        "image_path = \"/content/road_cracks.jpeg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcac Prepare Prompt and Process Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"Describe the image.\"\n",
        "inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd2e Generate Caption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generated_ids = model.generate(**inputs, max_new_tokens=50)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udda8\ufe0f Display Caption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\ud83d\uddbc\ufe0f Image Caption:\")\n",
        "print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}