{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72419184-0ee2-4477-ba50-7bd4e6458000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc0967-4e42-4908-94d9-a12fb159e0b3",
   "metadata": {},
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03aacfc8-1659-4256-b61a-3127d525a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenizer and Vocabulary Creation (Add more words if needed)\n",
    "sentence_en = \"I love Dhoni .\"\n",
    "# sentence_fr = \"J' adore l'IA .\"\n",
    "sentence_te = \"నాకు ధోని అంటే ఇష్టం .\"\n",
    "\n",
    "word_map_en = {\"<pad>\": 0, \"I\": 1, \"love\": 2, \"Dhoni\": 3, \".\": 4}\n",
    "word_map_te = {\"<pad>\": 0, \"నాకు\": 1, \"ధోని\": 2, \"అంటే\": 3, \"ఇష్టం\": 4, \".\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15935042-ab1f-4a5f-abc2-e64673bd2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing sentences\n",
    "def tokenize(sentence, word_map):\n",
    "    return torch.tensor([word_map[word] for word in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a89eca-f6f2-448b-bded-4c3c83819518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input and target sentences\n",
    "input_tensor = tokenize(sentence_en, word_map_en).unsqueeze(0)  # Shape (1, 4)\n",
    "target_tensor = tokenize(sentence_te, word_map_te).unsqueeze(0)  # Shape (1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d781ea9d-7d45-4e05-a066-540a4e5b254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4]), torch.Size([1, 5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1670dbe-04b9-4bab-bc90-2538db82c580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4]]), tensor([[1, 2, 3, 4, 5]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e83274-facd-4410-98d5-5c5bdddf53ac",
   "metadata": {},
   "source": [
    "# Task: Uses nn.Embedding to generate trainable word vectors for a given vocabulary of size vocab_size with d_model dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99aa9a61-158c-4652-88af-b626cfa6cc1f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-617750cc976f401c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(Transformer, self).__init__()\n",
    "        ### BEGIN SOLUTION\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "    def forward(self, src):\n",
    "        ### BEGIN SOLUTION\n",
    "        src_embedding = self.embedding(src)\n",
    "        ### END SOLUTION\n",
    "       \n",
    "        return src_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb0c856-0331-46f5-8621-46b448db6c93",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c445789abd204ac3",
     "locked": true,
     "points": 90,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Passed: Single word embedding shape is correct.\n",
      "Test 2 Passed: Multiple word embeddings shape is correct.\n",
      "Test 3 Passed: Batched input embeddings shape is correct.\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Test Function\n",
    "def test_transformer():\n",
    "    vocab_size = 10  # 10 words in vocabulary\n",
    "    d_model = 4      # Each word is represented by a 4D vector\n",
    "    model = Transformer(vocab_size, d_model)\n",
    "\n",
    "    # Test Case 1: Single Word Input\n",
    "    input_tensor = torch.tensor([2])  # Single index\n",
    "    output = model(input_tensor)\n",
    "    assert output.shape == (1, d_model), f\"Expected (1, {d_model}), got {output.shape}\"\n",
    "    print(\"Test 1 Passed: Single word embedding shape is correct.\")\n",
    "\n",
    "    # Test Case 2: Multiple Words (1D tensor)\n",
    "    input_tensor = torch.tensor([1, 3, 5])\n",
    "    output = model(input_tensor)\n",
    "    assert output.shape == (3, d_model), f\"Expected (3, {d_model}), got {output.shape}\"\n",
    "    print(\"Test 2 Passed: Multiple word embeddings shape is correct.\")\n",
    "\n",
    "    # Test Case 3: Batch of Sentences (2D tensor)\n",
    "    input_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Batch size = 2, Sequence length = 3\n",
    "    output = model(input_tensor)\n",
    "    assert output.shape == (2, 3, d_model), f\"Expected (2, 3, {d_model}), got {output.shape}\"\n",
    "    print(\"Test 3 Passed: Batched input embeddings shape is correct.\")\n",
    "    \n",
    "# Run Tests\n",
    "test_transformer()\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cb1744d-4c03-4c72-bf24-19417cf0092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize Model\n",
    "vocab_size_en = len(word_map_en)\n",
    "vocab_size_te = len(word_map_te)\n",
    "d_model = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93a644-9b71-4a55-b426-a508914032dc",
   "metadata": {},
   "source": [
    "# Task: Creates a Transformer model instance \"transformer\" that generates trainable word embeddings for a given English vocabulary size (vocab_size_en) with d_model-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebedd494-5298-47ba-b970-66d14612ad1d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-371d413bf75a514a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "transformer = Transformer(vocab_size_en, d_model)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190d1a8a-fb89-4bc1-a9df-641d7c757f2c",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8628e58db2eb4f8a",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed: Transformer model initialized correctly.\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Simple Test Case\n",
    "vocab_size_en = 10  # Example vocabulary size\n",
    "d_model = 16  # Embedding dimension\n",
    "\n",
    "# Initialize the Transformer model\n",
    "transformer_t = Transformer(vocab_size_en, d_model)\n",
    "\n",
    "# Check if the model is created successfully\n",
    "assert isinstance(transformer_t, Transformer), \" Test Failed: Model initialization incorrect.\"\n",
    "print(\"Test Passed: Transformer model initialized correctly.\")\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30eeb64-3d08-46cd-a956-02240dd90ee8",
   "metadata": {},
   "source": [
    "# Task: Stores the generated word embeddings in \"output\" by passing input_tensor through the Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c835e81-56ba-4f21-8a12-14f3e038be4f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f934042bd16d599",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "output = transformer(input_tensor)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d636f30-8731-4833-9d0b-a088eac8c845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6427,  1.0418, -1.9301, -0.5989, -1.6324,  0.0365, -1.7540,\n",
       "          -1.1726],\n",
       "         [ 0.6253, -0.6434, -0.8869,  0.1791, -1.0080,  0.6745,  0.6509,\n",
       "          -0.9106],\n",
       "         [ 0.4746, -1.1906,  0.0895, -1.1018, -0.3435,  0.3036,  0.6882,\n",
       "          -0.5738],\n",
       "         [-0.2207, -1.3925, -1.1076, -0.5746,  0.2375,  0.3075, -0.2857,\n",
       "           1.0026]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a639c-4b3d-42a8-8b42-5ef6f532092c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
