{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982428f4-693e-419f-a684-0d7473a4eed5",
   "metadata": {},
   "source": [
    "# Demonstrating Masked Self-Attention in Transformers\n",
    "## This notebook will provide an intuitive and practical demonstration of Masked Self-Attention in Transformers using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53eac97-2583-4e8b-8506-01b837f8834f",
   "metadata": {},
   "source": [
    "## Masked Self Attention\n",
    "\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a78fc9-b9b2-4c05-8766-17b41a788e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a09000-1d97-4fb7-a167-c9a095c39460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9402cf78f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(24)  # Python random seed\n",
    "torch.manual_seed(24)  # PyTorch seed (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dabcfc2-b41c-436b-8377-c8ebfb4c4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set print options: No scientific notation, 2 decimal places\n",
    "torch.set_printoptions(sci_mode=False, precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f73a90-9b75-4353-bbde-4185ee5044d9",
   "metadata": {},
   "source": [
    "# Define the maximum sequence length and the embedding dimension for a model:\n",
    "\n",
    "max_sequence_length = 5: Specifies the maximum number of tokens a sequence can have. If a sequence is shorter, it may be padded; if longer, it may be truncated.\n",
    "\n",
    "d_model = 8: Defines the size of each token’s embedding vector, meaning each token will be represented as a     8-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b41bf5e-0789-4d55-984a-e40711ffaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 8\n",
    "max_sequence_length = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a2a0b-a76d-4401-8c8f-65ea16528f70",
   "metadata": {},
   "source": [
    "# Define three linear layers using nn.Linear in PyTorch:\n",
    "\n",
    "w_query: Projects input embeddings into query space.\n",
    "\n",
    "w_key: Projects input embeddings into key space.\n",
    "\n",
    "w_value: Projects input embeddings into value space.\n",
    "## These linear layers transform input embeddings (d_model dimensional) into new representations of the same size (d_model → d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e321d39-8641-4f0a-afa1-ce49e260599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_query = nn.Linear(d_model, d_model)\n",
    "w_key   = nn.Linear(d_model, d_model)\n",
    "w_value = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766fa90-86b9-467e-a7fb-da2b5fdac577",
   "metadata": {},
   "source": [
    "# Create a tensor tokens with random values, scaled by a factor of 10.0, to simulate a sequence of token embeddings.\n",
    "\n",
    "Use torch.randn() to generate a random tensor of shape (max_sequence_length, d_model), where:\n",
    "\n",
    "max_sequence_length represents the number of tokens in the sequence.\n",
    "\n",
    "d_model represents the embedding dimension.\n",
    "\n",
    "Multiply the generated tensor by 10.0 to scale the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a599c7e-007f-43da-b48c-bf65e0a3bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.randn(max_sequence_length, d_model) * 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27cb32f2-fec9-4220-ac49-2009e9d5b6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c394140-2545-4b1d-8dda-2a42059ae728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.7217, -15.5080,  -9.5075,  -8.6397,  -2.1968,  -5.2217,   5.0664,\n",
       "           3.8816],\n",
       "        [ -3.8720, -20.7487,  18.5679,  -9.4431,  15.2684,  24.3474,  -9.0936,\n",
       "          -4.0998],\n",
       "        [ -1.2953,   8.7748, -12.0887,  -8.3205,   0.2548, -14.4027,  -2.6338,\n",
       "          -4.5473],\n",
       "        [  6.4649, -11.6771,  -1.0466,  12.9927,   9.8568,   0.3484,  -1.1219,\n",
       "          -0.6101],\n",
       "        [-18.4733,   3.4435,   4.8654, -22.3485,   8.1349,  27.0436,  20.6851,\n",
       "           6.2408]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e2b12-1877-4340-b0f6-4d2b1473bee9",
   "metadata": {},
   "source": [
    "# Apply linear transformations to the tokens tensor using w_query, w_key, and w_value to obtain query (q), key (k), and value (v) representations.\n",
    "\n",
    "## Pass tokens through the three linear layers to compute q, k, and v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00475ad2-51a4-4462-8d1a-976b5f04eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = w_query(tokens)\n",
    "k = w_key(tokens)\n",
    "v = w_value(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a36b478-8a8a-4407-a5f1-83462a95d20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 8]), torch.Size([5, 8]), torch.Size([5, 8]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ba828-35d6-481d-a798-4c8f1d4c95b8",
   "metadata": {},
   "source": [
    "## Masked Self Attention\n",
    "\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a797931e-a1ea-4876-b5d9-35e55677692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = torch.matmul(q, k.T) / torch.sqrt(torch.tensor(d_model, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c7926e6-c9fc-41a2-be0b-91d8b5ae4709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.9895, -56.4391, -31.7966,   5.9264, -43.4802],\n",
       "        [-59.5789,  -7.6356,  -0.6855,   0.2884,  80.4750],\n",
       "        [ 35.6549,  38.7697,   0.4983,  17.5775, -30.8585],\n",
       "        [ -5.2894, -47.0393, -29.2334,  -0.4237, -16.0637],\n",
       "        [-42.9926,  53.9101,  39.0516,   6.6710,  59.3816]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcad2e3b-8953-4f3c-a00c-41933c948b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fccc01b-93d2-47fc-a670-6ea00aa49c07",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "- This is to ensure words don't get context from words generated in the future.\n",
    "- Not required in the encoders, but required in the decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa8fa0-331c-4b05-a19a-2197d5f4509a",
   "metadata": {},
   "source": [
    "# Create a lower triangular mask using torch.tril, which generates a matrix where only the lower triangle (including the diagonal) contains ones, while the upper triangle contains zeros. This mask is typically used in masked self-attention in transformers to ensure that each position in a sequence can only attend to previous positions and itself, preventing access to future tokens during decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29f0f54-d133-4e5c-ab5c-dca0434ab589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones((max_sequence_length, max_sequence_length)))\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3092f-00d9-4fb5-8d39-1be3c82c28b3",
   "metadata": {},
   "source": [
    "# Apply a mask to the attention scores using masked_fill, setting positions where mask == 0 to -inf. This ensures that future tokens are ignored in masked self-attention, preventing the model from attending to unseen tokens during autoregressive decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19136a01-1288-468a-b817-d168300de44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0098be9-51e8-419f-a677-ccc470acb7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.9895,     -inf,     -inf,     -inf,     -inf],\n",
       "        [-59.5789,  -7.6356,     -inf,     -inf,     -inf],\n",
       "        [ 35.6549,  38.7697,   0.4983,     -inf,     -inf],\n",
       "        [ -5.2894, -47.0393, -29.2334,  -0.4237,     -inf],\n",
       "        [-42.9926,  53.9101,  39.0516,   6.6710,  59.3816]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d85b218a-5c9b-4c02-b867-d88ba84882ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = F.softmax(attn_scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da66f370-864b-448d-8721-41e54819d00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
       "        [    0.0425,     0.9575,     0.0000,     0.0000,     0.0000],\n",
       "        [    0.0076,     0.0000,     0.0000,     0.9924,     0.0000],\n",
       "        [    0.0000,     0.0042,     0.0000,     0.0000,     0.9958]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db34b539-46c2-4606-8e5d-aa10d8b545e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum = tensor([1., 1., 1., 1., 1.], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"sum = {attn_weights.sum(dim=-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c6c16-894f-4738-993a-b17609b5c4b7",
   "metadata": {},
   "source": [
    "# Compute the weighted sum of value (v) vectors using attention weights, where each query token receives a context-aware representation. This ensures that each generated token attends to relevant past tokens, influencing its prediction based on learned dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "955815d4-ca60-443f-9527-a3e43969b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output = torch.matmul(attn_weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aabe3469-53d5-4bd4-bb6b-e5c8950cff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98ed7b90-4efa-4faa-a3a2-d41c2a389bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.3459,  -1.6540,   7.7558,  -4.7189,   7.4060,   7.7708,  -3.1271,\n",
       "           0.6721],\n",
       "        [ 18.0213,   6.2609,   1.7086,   6.8319,  -1.5335,  -1.1946,   5.0538,\n",
       "          -2.8420],\n",
       "        [ 17.4401,   5.9245,   1.9657,   6.3410,  -1.1535,  -0.8136,   4.7061,\n",
       "          -2.6926],\n",
       "        [  1.4368,   5.7818,  -0.2100,  -6.2094,   0.9749,   4.3626,  -6.4292,\n",
       "           0.1822],\n",
       "        [ 13.0137,  -4.3577, -10.8564,  22.3291,  11.1974,  -8.0273,  19.4841,\n",
       "           3.5926]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f92cda-92ed-497b-b26e-e2756843154e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
