{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982428f4-693e-419f-a684-0d7473a4eed5",
   "metadata": {},
   "source": [
    "# Demonstrating Masked Self-Attention in Transformers\n",
    "## This notebook will provide an intuitive and practical demonstration of Masked Self-Attention in Transformers using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53eac97-2583-4e8b-8506-01b837f8834f",
   "metadata": {},
   "source": [
    "## Masked Self Attention\n",
    "\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a78fc9-b9b2-4c05-8766-17b41a788e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a09000-1d97-4fb7-a167-c9a095c39460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(24)  # Python random seed\n",
    "torch.manual_seed(24)  # PyTorch seed (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabcfc2-b41c-436b-8377-c8ebfb4c4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set print options: No scientific notation, 2 decimal places\n",
    "torch.set_printoptions(sci_mode=False, precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f73a90-9b75-4353-bbde-4185ee5044d9",
   "metadata": {},
   "source": [
    "# Define the maximum sequence length and the embedding dimension for a model:\n",
    "\n",
    "max_sequence_length = 5: Specifies the maximum number of tokens a sequence can have. If a sequence is shorter, it may be padded; if longer, it may be truncated.\n",
    "\n",
    "d_model = 8: Defines the size of each token’s embedding vector, meaning each token will be represented as a     8-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41bf5e-0789-4d55-984a-e40711ffaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 8\n",
    "max_sequence_length = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a2a0b-a76d-4401-8c8f-65ea16528f70",
   "metadata": {},
   "source": [
    "# Define three linear layers using nn.Linear in PyTorch:\n",
    "\n",
    "w_query: Projects input embeddings into query space.\n",
    "\n",
    "w_key: Projects input embeddings into key space.\n",
    "\n",
    "w_value: Projects input embeddings into value space.\n",
    "## These linear layers transform input embeddings (d_model dimensional) into new representations of the same size (d_model → d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e321d39-8641-4f0a-afa1-ce49e260599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_query = nn.Linear(d_model, d_model)\n",
    "w_key   = nn.Linear(d_model, d_model)\n",
    "w_value = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766fa90-86b9-467e-a7fb-da2b5fdac577",
   "metadata": {},
   "source": [
    "# Create a tensor tokens with random values, scaled by a factor of 10.0, to simulate a sequence of token embeddings.\n",
    "\n",
    "Use torch.randn() to generate a random tensor of shape (max_sequence_length, d_model), where:\n",
    "\n",
    "max_sequence_length represents the number of tokens in the sequence.\n",
    "\n",
    "d_model represents the embedding dimension.\n",
    "\n",
    "Multiply the generated tensor by 10.0 to scale the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a599c7e-007f-43da-b48c-bf65e0a3bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.randn(max_sequence_length, d_model) * 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb32f2-fec9-4220-ac49-2009e9d5b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c394140-2545-4b1d-8dda-2a42059ae728",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e2b12-1877-4340-b0f6-4d2b1473bee9",
   "metadata": {},
   "source": [
    "# Apply linear transformations to the tokens tensor using w_query, w_key, and w_value to obtain query (q), key (k), and value (v) representations.\n",
    "\n",
    "## Pass tokens through the three linear layers to compute q, k, and v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00475ad2-51a4-4462-8d1a-976b5f04eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = w_query(tokens)\n",
    "k = w_key(tokens)\n",
    "v = w_value(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36b478-8a8a-4407-a5f1-83462a95d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ba828-35d6-481d-a798-4c8f1d4c95b8",
   "metadata": {},
   "source": [
    "## Masked Self Attention\n",
    "\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797931e-a1ea-4876-b5d9-35e55677692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = torch.matmul(q, k.T) / torch.sqrt(torch.tensor(d_model, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7926e6-c9fc-41a2-be0b-91d8b5ae4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad2e3b-8953-4f3c-a00c-41933c948b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fccc01b-93d2-47fc-a670-6ea00aa49c07",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "- This is to ensure words don't get context from words generated in the future.\n",
    "- Not required in the encoders, but required in the decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa8fa0-331c-4b05-a19a-2197d5f4509a",
   "metadata": {},
   "source": [
    "# Create a lower triangular mask using torch.tril, which generates a matrix where only the lower triangle (including the diagonal) contains ones, while the upper triangle contains zeros. This mask is typically used in masked self-attention in transformers to ensure that each position in a sequence can only attend to previous positions and itself, preventing access to future tokens during decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f0f54-d133-4e5c-ab5c-dca0434ab589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa3092f-00d9-4fb5-8d39-1be3c82c28b3",
   "metadata": {},
   "source": [
    "# Apply a mask to the attention scores using masked_fill, setting positions where mask == 0 to -inf. This ensures that future tokens are ignored in masked self-attention, preventing the model from attending to unseen tokens during autoregressive decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19136a01-1288-468a-b817-d168300de44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0098be9-51e8-419f-a677-ccc470acb7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b218a-5c9b-4c02-b867-d88ba84882ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = F.softmax(attn_scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66f370-864b-448d-8721-41e54819d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db34b539-46c2-4606-8e5d-aa10d8b545e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sum = {attn_weights.sum(dim=-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c6c16-894f-4738-993a-b17609b5c4b7",
   "metadata": {},
   "source": [
    "# Compute the weighted sum of value (v) vectors using attention weights, where each query token receives a context-aware representation. This ensures that each generated token attends to relevant past tokens, influencing its prediction based on learned dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955815d4-ca60-443f-9527-a3e43969b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output = torch.matmul(attn_weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe3469-53d5-4bd4-bb6b-e5c8950cff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed7b90-4efa-4faa-a3a2-d41c2a389bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f92cda-92ed-497b-b26e-e2756843154e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
